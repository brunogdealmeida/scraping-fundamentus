{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "https://www.fundamentus.com.br/detalhes.php?papel=PINE4\n{'PINE4': ['PINE4', '3,10', 'PN', '24/07/2020', 'Pine PN', '1,53', 'Financeiros', '4,90', 'Bancos', '1.146.070', '459.290.000', '31/03/2020', '-', '148.158.000', '2,99%', '-5,76', '-0,54', '6,16%', '0,55', '5,68', '5,44%', '-', '-', '22,53%', '-', '-', '-26,19%', '-', '0,0%', '90,05%', '-', '0,0%', '-36,86%', '-', '-', '-11,62%', '0,0%', '-9,5%', '16,47%', '-', '-', '-31,73%', '-', '-', '-26,0%', '-', '11.330.000.000', 0, 0, 0, 0, '39.542.000', '35.151.000', '7.625.000', '-79.744.000', '-2.282.000', 0, 0, '6.312.290.000', '2.462.670.000']}\nhttps://www.fundamentus.com.br/detalhes.php?papel=BAZA3\n{'PINE4': ['PINE4', '3,10', 'PN', '24/07/2020', 'Pine PN', '1,53', 'Financeiros', '4,90', 'Bancos', '1.146.070', '459.290.000', '31/03/2020', '-', '148.158.000', '2,99%', '-5,76', '-0,54', '6,16%', '0,55', '5,68', '5,44%', '-', '-', '22,53%', '-', '-', '-26,19%', '-', '0,0%', '90,05%', '-', '0,0%', '-36,86%', '-', '-', '-11,62%', '0,0%', '-9,5%', '16,47%', '-', '-', '-31,73%', '-', '-', '-26,0%', '-', '11.330.000.000', 0, 0, 0, 0, '39.542.000', '35.151.000', '7.625.000', '-79.744.000', '-2.282.000', 0, 0, '6.312.290.000', '2.462.670.000'], 'BAZA3': ['BAZA3', '37,00', 'ON', '24/07/2020', 'BANCO DA AMAZONIA S.A. ON', '22,11', 'Financeiros', '39,82', 'Bancos', '127.019', '1.096.900.000', '31/03/2020', '-', '29.646.000', '-3,24%', '3,46', '10,70', '4,49%', '0,50', '74,40', '10,45%', '-', '-', '32,69%', '-', '-', '1,04%', '-', '0,0%', '75,52%', '-', '0,0%', '-2,48%', '-', '-', '-9,42%', '9,7%', '14,4%', '33,82%', '-', '-', '0,00%', '-', '-', '-7,9%', '-', '20.529.100.000', 0, 0, 0, 0, '90.343.000', '861.684.000', '223.363.000', '317.178.000', '33.100.000', 0, 0, '4.390.250.000', '3.119.100.000']}\n"
    }
   ],
   "source": [
    "#dict_data = collections.defaultdict(list)\n",
    "dict_data = {}\n",
    "\n",
    "with open(\"tickers.txt\", \"r\") as fundamentus_file:\n",
    "    stocks = fundamentus_file.read().split()\n",
    "    \n",
    "\n",
    "for stock in stocks:\n",
    "    list_data = []\n",
    "    time.sleep(20)\n",
    "    stock_url = 'https://www.fundamentus.com.br/detalhes.php?papel={}'.format(stock)\n",
    "\n",
    "    print(stock_url)\n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0\"}\n",
    "    page = rq.get(stock_url, headers=headers)\n",
    "    html = BeautifulSoup(page.text, 'html.parser')\n",
    "    #print(html)\n",
    "\n",
    "    #tables = html.select('table.w728')\n",
    "    #print(tables)\n",
    "    names = html.find_all('td', class_='label')\n",
    "    help_tips = html.find_all('span', class_='help tips')\n",
    "    help_tips2 = html.find_all('span', class_='title')\n",
    "    data = html.find_all('td', class_='data')\n",
    "\n",
    "\n",
    "    list_data.append(data[0].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[1].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[2].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[3].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[4].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[5].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[6].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[7].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[8].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[9].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[10].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[11].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[12].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[13].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[14].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[15].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[16].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[17].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[18].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[19].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[20].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[21].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[22].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[23].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[24].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[25].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[26].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[27].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[28].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[29].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[30].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[31].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[32].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[33].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[34].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[35].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[36].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[37].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[38].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[39].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[40].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[41].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[42].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[43].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[45].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[46].get_text().replace('\\n          ',''))\n",
    "    list_data.append(data[47].get_text().replace('\\n          ',''))\n",
    "    if len(data) == 59:\n",
    "        list_data.append(data[48].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[49].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[50].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[51].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[52].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[53].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[54].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[55].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[56].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[57].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[58].get_text().replace('\\n          ',''))\n",
    "        list_data.append(0)\n",
    "        list_data.append(0)\n",
    "    else:\n",
    "        list_data.append(0)\n",
    "        list_data.append(0)\n",
    "        list_data.append(0)\n",
    "        list_data.append(0)\n",
    "        list_data.append(data[52].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[53].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[54].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[55].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[56].get_text().replace('\\n          ',''))\n",
    "        list_data.append(0)\n",
    "        list_data.append(0)\n",
    "        list_data.append(data[48].get_text().replace('\\n          ',''))\n",
    "        list_data.append(data[49].get_text().replace('\\n          ',''))\n",
    "    \n",
    "    dict_data.update({stock:list_data})\n",
    "    print(dict_data)\n",
    "\n",
    "#print(dict_data)\n",
    "    \n",
    "\n",
    "df = pd.DataFrame.from_dict(dict_data, orient='index', columns=['ACAO','VALOR_ULTIMA_COTACAO','TIPO_ACAO','DATA_ULTIMA_COTACAO','NOME_COMERCIAL_EMPRESA','MENOR_COTACAO_12M','SETOR_ATUACAO','MAIOR_COTACAO_52S','SUBSETOR','VOLUME_MEDIO_NEGOC_2M','VALOR_MERCADO','ULTIMO_BALANCO','VALOR_FIRMA','NUMERO_ACOES','OSCILACAO_DIA','P/L','LPA','OSCILACAO_MES','P/VP','VPA','OSCILACAO_30D','P/EBIT','MARGEM_BRUTA','OSCILACAO_12M','PSR','MARGEM_EBIT','OSCILACAO_2020','P/ATIVOS','MARGEM_LIQUIDA','OSCILACAO_2019','P/CAPITAL_GIRO','EBIT/ATIVO','OSCILACAO_2018','P/ATIVO_CIRC_LIQ','ROIC','OSCILACAO_2017','DIVIDEND_YIELD','ROE','OSCILACAO_2016','EV/EBITDA','LIQUIDEZ_CORRENTE','OSCILACAO_2015','EV/EBIT','DIVIDA_BRUTA/PATRIMONIO','CRESCIMENTO_RECEITA_5A','GIRO_ATIVOS','ATIVO','DIVIDA_BRUTA','DISPONIBILIDADES','DIVIDA_LIQUIDA','ATIVO_CIRCULANTE','PATRIMONIO_LIQUIDO','RECEITA_LIQUIDA_12M','RECEITA_LIQUIDA_3M','EBIT_12M','EBIT_3M','LUCRO_LIQUIDO_12M','LUCRO_LIQUIDO_3M','DEPOSITOS','CART_DE_CREDITO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('fundamentus.xlsx', sheet_name='Base', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}